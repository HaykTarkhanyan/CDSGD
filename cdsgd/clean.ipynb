{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import datetime \n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import filter_by_rule\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s [%(levelname)s] %(message)s\", \n",
    "                    datefmt=\"%d-%b-%y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 17:40:01 [INFO] Found 1 datasets\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER = \"datasets\"\n",
    "\n",
    "assert os.path.exists(DATASET_FOLDER), \"Dataset folder not found\"\n",
    "\n",
    "datasets = os.listdir(DATASET_FOLDER)\n",
    "logging.info(f\"Found {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset, make checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 17:40:02 [INFO] ------ Dataset: Brain Tumor | Shape: (3762, 14) | Label ratio: 0.55 -------\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0]\n",
    "dataset_name = dataset.split(\".\")[0]\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_FOLDER, dataset))\n",
    "\n",
    "assert data.isna().sum().sum() == 0, \"Dataset contains missing values\"\n",
    "assert \"labels\" in data.columns, \"Dataset does not contain `labels` column\"\n",
    "assert data.labels.nunique() == 2, \"Dataset labels are not binary\"\n",
    "\n",
    "label_ratio = data.labels.value_counts(normalize=True).iloc[0]\n",
    "assert 0.4 < label_ratio < 0.6, \"Label ratio is not balanced\"\n",
    "\n",
    "# move labels column to the end \n",
    "data = data[[col for col in data.columns if col != \"labels\"] + [\"labels\"]]\n",
    "\n",
    "logging.info(f\"------ Dataset: {dataset_name} | Shape: {data.shape} | Label ratio: {label_ratio:.2f} -------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 18:10:27 [INFO] Step 0: Data split done | 2633 - 1129\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data = data.apply(pd.to_numeric)\n",
    "cut = int(train_set_size*len(data))\n",
    "\n",
    "train_data_df = data.iloc[:cut]\n",
    "test_data_df = data.iloc[cut:]\n",
    "\n",
    "X_train = data.iloc[:cut, :-1].values\n",
    "y_train = data.iloc[:cut, -1].values\n",
    "X_test = data.iloc[cut:, :-1].values\n",
    "y_test = data.iloc[cut:, -1].values\n",
    "\n",
    "logging.info(f\"Step 0: Data split done | {len(X_train)} - {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 17:40:03 [DEBUG] Step 1: Standard scaling complete\n"
     ]
    }
   ],
   "source": [
    "st_scaler = StandardScaler().fit(train_data_df)\n",
    "# break\n",
    "scale = st_scaler.scale_\n",
    "mean = st_scaler.mean_\n",
    "var = st_scaler.var_ \n",
    "\n",
    "X_train_scaled = st_scaler.transform(train_data_df)\n",
    "X_test_scaled = st_scaler.transform(test_data_df)  #! during inference we won't have this\n",
    "\n",
    "logging.debug(\"Step 1: Standard scaling complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 17:51:39 [INFO] Step 2: Performing clustering\n",
      "26-Apr-24 17:51:39 [DEBUG] Evaluation on train\n",
      "26-Apr-24 17:51:39 [DEBUG] \tsilhouette = 0.587\n",
      "26-Apr-24 17:51:39 [DEBUG] \tcalinski_harabasz = 4398.598\n",
      "26-Apr-24 17:51:39 [DEBUG] \tinertia = 237900920.42\n",
      "26-Apr-24 17:51:39 [DEBUG] Evaluation on test\n",
      "26-Apr-24 17:51:39 [DEBUG] \tsilhouette = 0.584\n",
      "26-Apr-24 17:51:39 [DEBUG] \tcalinski_harabasz = 1716.836\n",
      "26-Apr-24 17:51:39 [INFO] Step 2: Clustering done\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Step 2: Performing clustering\")\n",
    "\n",
    "CLUSTERING_ALG = \"kmeans\" # in future we'll add DBSCAN\n",
    "\n",
    "clustering_model = KMeans(n_clusters=2, random_state=42, n_init=\"auto\")      \n",
    "clustering_model.fit(X_train)  \n",
    "\n",
    "clustering_labels_train = clustering_model.predict(X_train)\n",
    "clustering_labels_test = clustering_model.predict(X_test)\n",
    "\n",
    "def evaluate_clustering(df, labels, model=None, alg=\"kmeans\", round_digits=3, \n",
    "                        print_results=False, dataset=\"train\"):\n",
    "    silhouette = silhouette_score(df, labels).round(round_digits)\n",
    "    calinski_harabasz = calinski_harabasz_score(df, labels).round(round_digits)\n",
    "    \n",
    "    if alg == \"kmeans\" and dataset==\"train\":\n",
    "        inertia = round(model.inertia_,round_digits)\n",
    "        \n",
    "    \n",
    "    if print_results:\n",
    "        logging.debug(f\"Evaluation on {dataset}\")\n",
    "        logging.debug(f\"\\t{silhouette = }\")\n",
    "        logging.debug(f\"\\t{calinski_harabasz = }\")\n",
    "        if alg == \"kmeans\" and dataset==\"train\":\n",
    "            logging.debug(f\"\\t{inertia = }\")\n",
    "    \n",
    "evaluate_clustering(X_train, clustering_labels_train, clustering_model, \n",
    "                    CLUSTERING_ALG, print_results=True)\n",
    "evaluate_clustering(X_test, clustering_labels_test, clustering_model, \n",
    "                    CLUSTERING_ALG, print_results=True, dataset=\"test\")\n",
    "\n",
    "logging.info(\"Step 2: Clustering done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def swap_ones_zeros_decorator(func):\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         # Run the function in the ordinary way\n",
    "#         print(kwargs)\n",
    "#         result = func(*args, **kwargs)\n",
    "        \n",
    "#         # Swap 1s and 0s in y_clust\n",
    "#         kwargs[\"y_clust\"] = [1 if label == 0 else 0 for label in kwargs['y_clust']]\n",
    "#         swapped_result = func(*args, **kwargs)\n",
    "        \n",
    "#         # Return the best result (highest accuracy)\n",
    "#         if swapped_result['accuracy'] > result['accuracy']:\n",
    "#             return swapped_result\n",
    "#         else:\n",
    "#             return result\n",
    "    \n",
    "#     return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_classifier(*, y_actual, y_clust, dataset=\"train\", print_results=False,\n",
    "                        purpose=\"clustering_eval\"):    \n",
    "    accuracy = accuracy_score(y_actual, y_clust)\n",
    "    if purpose == \"clustering_eval\":\n",
    "        if accuracy < 0.5: # swap 1's and 0's\n",
    "            y_clust = [1 if label == 0 else 0 for label in y_clust]\n",
    "            accuracy = accuracy_score(y_actual, y_clust)\n",
    "\n",
    "    f1 = f1_score(y_actual, y_clust)\n",
    "    conf_matrix = confusion_matrix(y_actual, y_clust)\n",
    "    \n",
    "    if print_results:\n",
    "        logging.debug(f\"Evaluation on {dataset}\")\n",
    "        logging.debug(f\"\\tAccuracy:  {accuracy:.2f}\")\n",
    "        logging.debug(f\"\\tF1 Score: {f1:.2f}\")\n",
    "        logging.debug(f\"\\tConfusion Matrix: \\n{conf_matrix}\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"confusion_matrix\": conf_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Apr-24 18:08:52 [DEBUG] Evaluation on train\n",
      "26-Apr-24 18:08:52 [DEBUG] \tAccuracy:  0.65\n",
      "26-Apr-24 18:08:52 [DEBUG] \tF1 Score: 0.52\n",
      "26-Apr-24 18:08:52 [DEBUG] \tConfusion Matrix: \n",
      "[[1222  227]\n",
      " [ 685  499]]\n",
      "26-Apr-24 18:08:52 [DEBUG] Evaluation on test\n",
      "26-Apr-24 18:08:52 [DEBUG] \tAccuracy:  0.68\n",
      "26-Apr-24 18:08:52 [DEBUG] \tF1 Score: 0.54\n",
      "26-Apr-24 18:08:52 [DEBUG] \tConfusion Matrix: \n",
      "[[551  79]\n",
      " [285 214]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6775907883082374,\n",
       " 'f1': 0.5404040404040404,\n",
       " 'confusion_matrix': array([[551,  79],\n",
       "        [285, 214]], dtype=int64)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classifier(y_actual=y_train, y_clust=clustering_labels_train, \n",
    "                    dataset=\"train\", print_results=True)\n",
    "evaluate_classifier(y_actual=y_test, y_clust=clustering_labels_test, \n",
    "                    dataset=\"test\", print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
